# -*- coding: utf-8 -*-
"""wgan-cgan.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DbEXiYZz9POPV3K54S_fO2b7AmuAcAII
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import imageio
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import (Activation, BatchNormalization, Concatenate, Dense, Embedding, Flatten, Input, Multiply,
                                     Reshape, LeakyReLU, Conv2D, Conv2DTranspose)
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model
from tensorflow.keras import activations
from tensorflow.keras.constraints import Constraint
from tensorflow.keras import backend as K
from numpy import asarray, linspace
from numpy.random import randn, randint
from tensorflow.keras.utils import to_categorical
import numpy
from matplotlib import pyplot

batch_size = 1
num_channels = 1
num_classes = 5
image_size = 600
latent_dim = 128

generator_in_channels = latent_dim + num_classes # 128+5
discriminator_in_channels = num_channels + num_classes #1+5
print(generator_in_channels, discriminator_in_channels)

#carga un conjunto de datos de imágenes desde un directorio
train_x=tf.keras.utils.image_dataset_from_directory("/content/drive/MyDrive/binario/T2",labels="inferred", label_mode="int",
        color_mode="grayscale", batch_size=6000, image_size=(image_size, image_size), shuffle=True, seed=None,
        validation_split=None, subset=None, interpolation="bilinear", follow_links=False, crop_to_aspect_ratio=False)

# asigna a la variable class_names los nombres de las clases encontradas
class_names = train_x.class_names
print(class_names)

#Separo la etiqueta y la imagen. #x_train
x_train, y_train = next(iter(train_x))
all_digits=np.array(x_train)
all_labels=np.array(y_train)

all_digits = all_digits.astype("float32") / 127.5-1.0 #escalar los valores de píxeles en el rango [-1, 1].
all_digits = np.reshape(all_digits, (-1, image_size, image_size, 1)) # agregamos una dimensión adicional (para el canal).
all_labels = tf.keras.utils.to_categorical(all_labels, num_classes) #crea una matriz de forma (N, num_classes), donde N es el número de etiquetas en all_labels. Cada fila de la matriz representa una etiqueta y contiene solo ceros y unos. El uno se coloca en la posición correspondiente a la clase a la que pertenece la etiqueta, y los demás elementos de la fila se establecen en cero.

# Create tf.data.Dataset.
dataset = tf.data.Dataset.from_tensor_slices((all_digits, all_labels)) # Cada elemento del conjunto de datos es una tupla que contiene una imagen y su etiqueta correspondiente.
dataset = dataset.shuffle(buffer_size=100).batch(batch_size) #Esta línea realiza la transformación del conjunto de datos. Primero, se realiza una operación de mezcla (shuffle) en el conjunto de datos utilizando un tamaño de búfer de 100, lo que aleatoriza el orden de los elementos. Luego, se agrupan los elementos en lotes del tamaño batch_size.

print(f"Shape of training images: {all_digits.shape}")
print(f"Shape of training labels: {all_labels.shape}")

for i in range(1):
  i=0
  a=i
  print(a)
  img = all_digits[a,:].reshape(image_size,image_size) # First image in the training set.
  print(all_labels[a])
  plt.imshow(img,cmap='gray')
  plt.show() # Show the image

def make_discriminator():
    discriminator = tf.keras.Sequential(
        [
            tf.keras.layers.InputLayer((image_size, image_size, discriminator_in_channels)), #se define la capa de entrada
            tf.keras.layers.Conv2D(32, (5), strides=(2), padding="same"), #Defino una capa de convolución 2D con 32 filtros, una ventana de convolución de tamaño (5x5), un desplazamiento de (2,2)
            tf.keras.layers.LeakyReLU(alpha=0.01), #funcion de activación LeakyReLU con un parámetro de inclinación 0.01
            tf.keras.layers.Dropout(0.3), #capa de regularizaciónt con una tasa  de 0.3 para prevenir el sobreajuste
            tf.keras.layers.Conv2D(64, (5), strides=(2), padding="same"),
            #tf.keras.layers.ZeroPadding2D(padding=((0,1),(0,1))), # capa de relleno
            tf.keras.layers.LeakyReLU(alpha=0.01),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding="same"),
            tf.keras.layers.LeakyReLU(alpha=0.01),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding="same"),
            tf.keras.layers.LeakyReLU(alpha=0.01),
            tf.keras.layers.Dropout(0.3),
            tf.keras.layers.Flatten(), #capa de aplanamiento que convierte los datos de entrada en un vector unidimensional.
            tf.keras.layers.Dense(1), # Esta capa produce la salida final del modelo de discriminador.
        ],
        name="discriminator",
    )
    return discriminator


discriminator = make_discriminator()
tf.keras.utils.plot_model(discriminator, show_shapes=True, expand_nested=True)

def make_generator():
  generator = keras.Sequential(
    [
        keras.layers.InputLayer((generator_in_channels,)), #capa de entrada del modelo con el número de canales 128+5
        layers.Dense(75 * 75 * 600,input_dim=generator_in_channels), #Esta línea define una capa densa totalmente conectada
        layers.Reshape((75, 75, 600)), #Esta línea redefine la forma de la salida de la capa anterior a (75, 75, 600).
        layers.Conv2DTranspose(128, kernel_size=(5, 5), strides=(2, 2), padding="same"), #capa de convolución transpuesta con 128 filtros, un tamaño de kernel de (5x5), un desplazamiento de (2,2)
        layers.BatchNormalization(), #capa de normalización de lotes. media cero y varianza unitaria
        layers.LeakyReLU(alpha=0.01),
        layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding="same"),
        layers.BatchNormalization(),
        layers.LeakyReLU(alpha=0.01),
        layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding="same"),
        layers.BatchNormalization(),
        layers.LeakyReLU(alpha=0.01),
        layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding="same"),
        layers.BatchNormalization(),
        layers.LeakyReLU(alpha=0.01),
        layers.Conv2D(1, kernel_size=(5, 5), strides=(2, 2), padding="same"),
        layers.Activation('tanh')
    ],
    name='generator',
  )
  return generator

generator = make_generator()
tf.keras.utils.plot_model(generator, show_shapes=True, expand_nested=True)

class WGAN_GP(tf.keras.Model):
    def __init__(self, discriminator, generator, latent_dim): # Se define la funcion init con 3 parametros
		    super(WGAN_GP, self).__init__()  #Esta linea llama al metodo de inicializacion de la clase base tf.keras.Model.
		    self.discriminator = discriminator #Asigna el discriminador
		    self.generator = generator #Asigna el generador
		    self.latent_dim = latent_dim #Asigna la dimension latente
		    self.gen_loss_tracker = tf.keras.metrics.Mean(name="generator_loss") #Crea una metrica para  el valor medio de la perdida del generador
		    self.disc_loss_tracker = tf.keras.metrics.Mean(name="discriminator_loss") #Crea una metrica para  el valor medio de la perdida del discriminador

    @property
    def metrics(self):
        return [self.gen_loss_tracker, self.disc_loss_tracker]

    def compile(self, d_optimizer, g_optimizer, d_loss_fn):
        super(WGAN_GP, self).compile()
        self.d_optimizer = d_optimizer
        self.g_optimizer = g_optimizer
        self.d_loss_fn = d_loss_fn

    def gradient_penalty(self, batch_size, real_images, fake_images, one_hot_labels):
        """Calcula la penalización por gradiente."""
        alpha = tf.random.uniform([batch_size, 1, 1, 1], 0., 1.)
        interpolated_images = real_images * alpha + fake_images * (1 - alpha)

        with tf.GradientTape() as tape:
            tape.watch(interpolated_images)
            interpolated_image_and_labels = tf.concat([interpolated_images, one_hot_labels], -1)
            discriminator_interpolated = self.discriminator(interpolated_image_and_labels)
        gradients = tape.gradient(discriminator_interpolated, interpolated_images)
        slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), axis=[1, 2, 3]))
        gradient_penalty = tf.reduce_mean((slopes - 1.) ** 2)
        return gradient_penalty

    def train_step(self, data):
        # Descomprimir los datos.
        real_images, one_hot_labels = data

        # Agregue dimensiones ficticias a las etiquetas para que puedan concatenarse con las imagenes. Esto es para el discriminador.
        image_one_hot_labels = one_hot_labels[:, :, None, None]  # (64, 10, 1, 1)
        image_one_hot_labels = tf.repeat(image_one_hot_labels, repeats=[image_size * image_size] )
        image_one_hot_labels = tf.reshape( image_one_hot_labels, (-1, num_classes, image_size, image_size) )  # (64, 10, 28, 28)

        image_one_hot_labels = tf.transpose(image_one_hot_labels, (0, 2, 3, 1))  # (64, 28, 28, 10)

        # Muestra puntos aleatorios en el espacio latente y concatena las etiquetas.
        # Esto es para el generador.
        batch_size = tf.shape(real_images)[0]
        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))
        random_vector_labels = tf.concat( [random_latent_vectors, one_hot_labels], axis=1 )  # (64, 138)

        # Decodifica el ruido (guiado por etiquetas) a imagenes falsas.
        generated_images = self.generator(random_vector_labels)  # (64, 28, 28, 1)

        # Combinalos con imagenes reales.
        fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)  # (64, 28, 28, 11)
        real_image_and_labels = tf.concat([real_images, image_one_hot_labels], -1)

        combined_images = tf.concat( [fake_image_and_labels, real_image_and_labels], axis=0 )  # (128, 28, 28, 11)


        labels = tf.concat([tf.ones((batch_size, 1)), -tf.ones((batch_size, 1))], axis=0)  # (128, 1)

           # Entrenar al discriminador.
        with tf.GradientTape() as tape:
                fake_preds = self.discriminator(fake_image_and_labels)
                real_preds = self.discriminator(real_image_and_labels)
                d_loss = self.d_loss_fn(real_preds, fake_preds)
                gp = self.gradient_penalty(batch_size, real_images, generated_images, image_one_hot_labels)
                d_loss = d_loss + 10. * gp
        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)
        self.d_optimizer.apply_gradients(
            zip(grads, self.discriminator.trainable_weights)
        )

           # Muestrear los puntos aleatorios en el espacio latente.
        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))  # (64, 128)
        random_vector_labels = tf.concat(
            [random_latent_vectors, one_hot_labels], axis=1
        )  # (64, 138)

        # Reúna etiquetas que digan "todas las imágenes reales".
        misleading_labels = -tf.ones((batch_size, 1))  # (64, 1)

        # Entrene al generador (tenga en cuenta que *no* debemos actualizar los pesos del discriminador)!
        with tf.GradientTape() as tape:
            fake_images = self.generator(random_vector_labels)  # (64, 28, 28, 1)
            fake_image_and_labels = tf.concat([fake_images, image_one_hot_labels], -1)  # (64, 28, 28, 11)
            predictions = self.discriminator(fake_image_and_labels)  # (64, 1)
            g_loss = -tf.reduce_mean(predictions)
        grads = tape.gradient(g_loss, self.generator.trainable_weights)
        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))

        # Monitor loss.
        self.gen_loss_tracker.update_state(g_loss)
        self.disc_loss_tracker.update_state(d_loss)
        return {
        "g_loss": self.gen_loss_tracker.result(),
        "d_loss": self.disc_loss_tracker.result(),
        }

def check_generator(generator, n=1):
    _, one_hot_labels = next(iter(dataset))

    image_one_hot_labels = one_hot_labels[:, :, None, None]
    image_one_hot_labels = tf.repeat(
        image_one_hot_labels, repeats=[image_size * image_size])
    image_one_hot_labels = tf.reshape(image_one_hot_labels, (-1, num_classes, image_size, image_size))
    image_one_hot_labels = tf.transpose(image_one_hot_labels, (0, 2, 3, 1))

    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))

    random_vector_labels = tf.concat([random_latent_vectors, one_hot_labels], axis=1)

    generated_images = generator(random_vector_labels)

    fake_image_and_labels = tf.concat([generated_images, image_one_hot_labels], -1)

    for k in np.random.randint(0, batch_size, n):

        label = np.where(image_one_hot_labels[k][0, 0])[0][0]
        print('k: {}, label: {}'.format(k ,label))
        fake_image_and_label = fake_image_and_labels[k]
        print('fake_image_and_label: {}'.format(fake_image_and_label.shape))

        plt.imshow(fake_image_and_label[:, :, 0],cmap='gray')
        plt.show()

        fig, ax = plt.subplots(1, 5, figsize=(10, 4))
        ax=np.array([ax])
        for pos, channel in enumerate(range(1, 6)):
            im = fake_image_and_label[:, :, channel]
            i, j = pos // 5, pos % 5
            ax[i, j].imshow(im, vmin=0, vmax=1)
            ax[i, j].set_xticks([])
            ax[i, j].set_yticks([])
        plt.show()

check_generator(generator)

def discriminator_loss(real_preds, fake_preds):
    real_loss = tf.reduce_mean(real_preds)
    fake_loss = tf.reduce_mean(fake_preds)
    return fake_loss - real_loss

def generator_loss(fake_preds):
    return -tf.reduce_mean(fake_preds)

wgan_gp = WGAN_GP( discriminator=discriminator, generator=generator, latent_dim=latent_dim )

wgan_gp.compile(
d_optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00005),
g_optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.00005),
 d_loss_fn=discriminator_loss,
)

total_epochs = 0
print('#####################################')
print('### epochs: {}\n'.format(total_epochs))

check_generator(generator, n=1)

for epochs in [1, 0]:
    wgan_gp.fit(dataset, epochs=epochs)



#GUARDO EL MODELO PARA NO ENTRENAR CADA VEZ   './drive/MyDrive/binario/keras_mnist_cgan2.h5'
#model=wgan_gp
#model.save_weights(filepath= './drive/MyDrive/binario/600/weights_T2.h5', overwrite=True, save_format=None, options=None)
#discriminator.save("./drive/MyDrive/binario/600/dis_prueba_T2.h5")
#generator.save("./drive/MyDrive/binario/600/gen_prueba_T2.h5")

#Cargamos el modelo
model=wgan_gp
model.built = True
weights = model.load_weights(filepath='./drive/MyDrive/binario/600/weights_T2.h5')
discriminator = load_model("./drive/MyDrive/binario/600/dis_prueba_T2.h5")
generator = load_model("./drive/MyDrive/binario/600/gen_prueba_T2.h5")

# We first extract the trained generator from our Conditiona GAN.
trained_gen = wgan_gp.generator

# Elija el número de imágenes intermedias que se generarían en
# entre la interpolación + 2 (imágenes inicial y última).
num_interpolation = 3 # param {type:"integer"}

# Sample noise for the interpolation.
#tf.random.uniform( shape, minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None) interpolation_noise = tf.random.normal(shape=(batch_size, latent_dim), mean=0,stddev=0.2)
interpolation_noise = tf.random.normal(shape=(batch_size, latent_dim), mean=0.7,stddev=1.5)# interpolation_noise = tf.random.uniform(shape=(batch_size, latent_dim),minval=0, maxval=0.5, dtype=tf.dtypes.float32, seed=None, name=None)
interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)
interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))


def interpolate_class(first_number, second_number):
    # Convert the start and end labels to one-hot encoded vectors.
    first_label = keras.utils.to_categorical([first_number], num_classes)
    second_label = keras.utils.to_categorical([second_number], num_classes)
    first_label = tf.cast(first_label, tf.float32)
    second_label = tf.cast(second_label, tf.float32)

    # Calculate the interpolation vector between the two labels.
    percent_second_label = tf.linspace(0, 1, num_interpolation)[:, None]
    percent_second_label = tf.cast(percent_second_label, tf.float32)
    interpolation_labels = (
        first_label * (1 - percent_second_label) + second_label * percent_second_label
    )

    # Combine the noise and the labels and run inference with the generator.
    noise_and_labels = tf.concat([interpolation_noise, interpolation_labels], 1)
    fake = trained_gen.predict(noise_and_labels)
    fake=0.5*fake+0.5
    return fake


start_class = 2  # param {type:"slider", min:0, max:9, step:1}
end_class = 2 # param {type:"slider", min:0, max:9, step:1}

fake_images = interpolate_class(start_class, end_class)

fake_images *= 255.0
converted_images = fake_images.astype(np.uint8)
converted_images = tf.image.resize(converted_images, (600, 600)).numpy().astype(np.uint8)
#imageio.mimsave("animation.gif", converted_images, fps=1)
print(numpy.shape(converted_images))

interpol=converted_images[1]
img = keras.preprocessing.image.array_to_img(interpol)


# plot images
fig, axs = plt.subplots(1, num_interpolation,figsize=(30, 30), sharey=True,sharex=True)
for i in range(num_interpolation):
    # define subplot
    pyplot.subplot(1, num_interpolation, 1 + i)
    # turn off axis
    pyplot.axis('off')
    # plot raw pixel data
    #fig, axs = plt.subplots(1, 2,figsize=(3, 1),sharey=True,sharex=True)
    pyplot.imshow(converted_images[i, :, :, 0],cmap='gray')
    i+=1
pyplot.show()

lll=0

numer=1
for ip in range(numer):
  # We first extract the trained generator from our Conditiona GAN.
  trained_gen = wgan_gp.generator

  # Elija el número de imágenes intermedias que se generarían en
  # entre la interpolación + 2 (imágenes inicial y última).
  num_interpolation = 3 # param {type:"integer"}

  # Sample noise for the interpolation.
  interpolation_noise = tf.random.normal(shape=(batch_size, latent_dim), mean=0.6,stddev=0.7)
  interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)
  interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))




  start_class =3 # param {type:"slider", min:0, max:9, step:1}
  end_class =3 # param {type:"slider", min:0, max:9, step:1}

  fake_images = interpolate_class(start_class, end_class)

  fake_images *= 255.0
  converted_images = fake_images.astype(np.uint8)
  converted_images = tf.image.resize(converted_images, (600, 600)).numpy().astype(np.uint8)
  imageio.mimsave("animation.gif", converted_images, fps=1)
  print(numpy.shape(converted_images))

  interpol=converted_images[1]
  img = keras.preprocessing.image.array_to_img(interpol)




  interpol=converted_images[1]
  img = keras.preprocessing.image.array_to_img(interpol)
  img.save("/content/drive/MyDrive/binario/generadas/evolucion/image_{i}.png".format(i=lll))

  #interpol=converted_images[1]
  #img = keras.preprocessing.image.array_to_img(interpol)
  #img.save("/content/drive/MyDrive/binario/generadas/0.05_2/image_{i}.png".format(i=lll))

  #interpol=converted_images[2]
  #img = keras.preprocessing.image.array_to_img(interpol)
  #img.save("/content/drive/MyDrive/binario/generadas/0.05_3/image_{i}.png".format(i=lll))

  lll+=1

import math
rho=0.45 # @param {type:"slider", min:0.05, max:0.45, step:0.05}
rho_entero=rho*100
rho_2=rho*10

if rho_entero % 10 == 0:
    print("Interpolado")
    abc=rho_2
    start_class = abc-1
    end_class =abc

else:
    print(f"Base de datos")
    abc=math.floor(rho_2)
    start_class = abc
    end_class = abc

num_interpolation = 3 # param {type:"integer"}
# Sample noise for the interpolation.
#tf.random.uniform( shape, minval=0, maxval=None, dtype=tf.dtypes.float32, seed=None, name=None) interpolation_noise = tf.random.normal(shape=(batch_size, latent_dim), mean=0,stddev=0.2)
interpolation_noise = tf.random.normal(shape=(batch_size, latent_dim), mean=0.6,stddev=0.7)# interpolation_noise = tf.random.uniform(shape=(batch_size, latent_dim),minval=0, maxval=0.5, dtype=tf.dtypes.float32, seed=None, name=None)
interpolation_noise = tf.repeat(interpolation_noise, repeats=num_interpolation)
interpolation_noise = tf.reshape(interpolation_noise, (num_interpolation, latent_dim))
fake_images = interpolate_class(start_class, end_class)
fake_images *= 255.0
converted_images = fake_images.astype(np.uint8)
converted_images = tf.image.resize(converted_images, (600, 600)).numpy().astype(np.uint8)
interpol = converted_images[1]
img = keras.preprocessing.image.array_to_img(interpol)
# Muestra solo la figura intermedia
plt.figure(figsize=(8, 8))
plt.axis('off')
plt.imshow(converted_images[1, :, :, 0], cmap='gray')
plt.show()